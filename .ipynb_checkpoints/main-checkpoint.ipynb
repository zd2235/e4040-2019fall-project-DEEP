{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#######################\n",
    "# Reference site: https://towardsdatascience.com/beginners-guide-to-building-neural-networks-in-tensorflow-dab7a09b941d\n",
    "#######################\n",
    "\n",
    "# Use the CIFAR100 dataset(32*32) provided in keras for test\n",
    "# Note that Mobile Net limits the size of small crops so this shouldn't be appropriate in real apps\n",
    "cifar100 = tf.keras.datasets.cifar100\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# keras layers default input shape: (batch, height, width, channels)\n",
    "# or else need to declare\n",
    "# data_format = channels_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 16, 16, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 64)        2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_1 (Depthwis (None, 8, 8, 64)          640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 128)         8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_2 (Depthwis (None, 8, 8, 128)         1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_3 (Depthwis (None, 4, 4, 128)         1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 256)         33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_4 (Depthwis (None, 4, 4, 256)         2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 256)         65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_10 (ReLU)              (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_5 (Depthwis (None, 2, 2, 256)         2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_11 (ReLU)              (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_6 (Depthwis (None, 2, 2, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_14 (ReLU)              (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_7 (Depthwis (None, 2, 2, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_15 (ReLU)              (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 512)         262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_16 (ReLU)              (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_8 (Depthwis (None, 2, 2, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_17 (ReLU)              (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 2, 512)         262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_18 (ReLU)              (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_9 (Depthwis (None, 2, 2, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_19 (ReLU)              (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 2, 512)         262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_20 (ReLU)              (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_10 (Depthwi (None, 2, 2, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_21 (ReLU)              (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 512)         262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_22 (ReLU)              (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_11 (Depthwi (None, 1, 1, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_23 (ReLU)              (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 1, 1, 1024)        525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "re_lu_24 (ReLU)              (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_12 (Depthwi (None, 1, 1, 1024)        10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "re_lu_25 (ReLU)              (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 1, 1, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "re_lu_26 (ReLU)              (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 1, 100)         102500    \n",
      "=================================================================\n",
      "Total params: 3,342,308\n",
      "Trainable params: 3,320,420\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# dizzy with tf.get_Variable, name scope, etc. I used keras instead\n",
    "# change to tf.nn.con2d / tf.nn.depthwise_con2d, etc. if necessary\n",
    "\n",
    "# Set hyperparameters\n",
    "alpha = 1\n",
    "rho = 1\n",
    "\n",
    "# build the moblie net architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    # input conv\n",
    "        # input shape need to be declared (for test, 32*32; for ImageNet, 224*224)\n",
    "    tf.keras.layers.Conv2D(input_shape=(32, 32, 3),filters=32*alpha,kernel_size=3,strides=(2,2),padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # 1 depthwise separable conv\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3,strides=(1,1),padding=\"same\",depth_multiplier=1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Conv2D(filters=64*alpha,kernel_size=1,strides=(1,1),padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # 2\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3,strides=(2,2),padding=\"same\",depth_multiplier=1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Conv2D(filters=128*alpha,kernel_size=1,strides=(1,1),padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # 3\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3,strides=(1,1),padding=\"same\",depth_multiplier=1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Conv2D(filters=128*alpha,kernel_size=1,strides=(1,1),padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # 4\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3,strides=(2,2),padding=\"same\",depth_multiplier=1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Conv2D(filters=256*alpha,kernel_size=1,strides=(1,1),padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # 5\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3,strides=(1,1),padding=\"same\",depth_multiplier=1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Conv2D(filters=256*alpha,kernel_size=1,strides=(1,1),padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # 6\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3,strides=(2,2),padding=\"same\",depth_multiplier=1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Conv2D(filters=512*alpha,kernel_size=1,strides=(1,1),padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # 7*5\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3,strides=(1,1),padding=\"same\",depth_multiplier=1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Conv2D(filters=512*alpha,kernel_size=1,strides=(1,1),padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3,strides=(1,1),padding=\"same\",depth_multiplier=1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Conv2D(filters=512*alpha,kernel_size=1,strides=(1,1),padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3,strides=(1,1),padding=\"same\",depth_multiplier=1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Conv2D(filters=512*alpha,kernel_size=1,strides=(1,1),padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3,strides=(1,1),padding=\"same\",depth_multiplier=1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Conv2D(filters=512*alpha,kernel_size=1,strides=(1,1),padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3,strides=(1,1),padding=\"same\",depth_multiplier=1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Conv2D(filters=512*alpha,kernel_size=1,strides=(1,1),padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # 8\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3,strides=(2,2),padding=\"same\",depth_multiplier=1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Conv2D(filters=1024*alpha,kernel_size=1,strides=(1,1),padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # 9 -- Problelm: why the size of output doesn't change with stride = 2 in the article ???\n",
    "    # at this layer, the output size should be 1/2 after passing the depthwise conv\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3,strides=(2,2),padding=\"same\",depth_multiplier=1),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Conv2D(filters=1024*alpha,kernel_size=1,strides=(1,1),padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # pooling : pool_size according to the output size of #9, so that the result is (1,1,1024)\n",
    "        # In article, input(224,224) -> pool_size=(7,7)\n",
    "        # test phase, input(32,32) -> pool_size=(1,1)\n",
    "    tf.keras.layers.AveragePooling2D(pool_size=(1,1)),\n",
    "    \n",
    "    # FC layer, 1024 -> class #\n",
    "        # In article, ImageNet data set has 1000 classes\n",
    "        # For test, 100 classes\n",
    "    tf.keras.layers.Dense(100, activation='softmax')\n",
    "])\n",
    "\n",
    "# show the net structure and parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization step \n",
    "#(or called compile the model in keras)\n",
    "\n",
    "# Note that 'rmsprop' is using the default params, to change, use code below\n",
    "#rmsprop = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "50000/50000 [==============================] - 650s 13ms/sample - loss: 4.6290 - accuracy: 0.0102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1506dd49240>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "# just runned 1 epoch, loss 5.3 -> 4.6\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
